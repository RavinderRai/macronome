"""
Configuration for data ingestion scripts
"""

from pathlib import Path

# Get repo root (this file is in src/macronome/data_engineering/)
# Go up: data_engineering -> macronome -> src -> repo_root
REPO_ROOT = Path(__file__).parent.parent.parent.parent

# Kaggle dataset identifiers
RECIPENLG_DATASET = "paultimothymooney/recipenlg"

# Local paths (absolute paths from repo root)
DATA_DIR = REPO_ROOT / "data"
RECIPES_DIR = DATA_DIR / "recipes"
RECIPES_RAW_DIR = RECIPES_DIR / "raw"
RECIPES_PROCESSED_DIR = RECIPES_DIR / "processed"

# Output file names
RECIPES_PARQUET = "recipes.parquet"
EMBEDDINGS_FAISS = "embeddings.faiss"
EMBEDDINGS_INDEX = "embeddings.index"
METADATA_JSON = "metadata.json"

# Embedding configuration
EMBEDDING_MODEL = "sentence-transformers/all-MiniLM-L6-v2"
EMBEDDING_BATCH_SIZE = 512  # Increased for better MPS/GPU utilization
MAX_TEXT_LENGTH = 512  # Max tokens for embedding (legacy, not used in new format)

# Chunking configuration (for streaming large datasets)
RECIPE_CHUNK_SIZE = 10_000  # Process 10k recipes at a time to avoid OOM
QDRANT_UPLOAD_BATCH_SIZE = 1000  # Upload 1000 vectors at a time (much faster than 100)

# Embedding format: title + ingredients (no directions)
# This format matches the descriptive queries generated by the planning agent

# Recipe processing
MIN_INGREDIENTS = 2  # Filter out recipes with too few ingredients
MIN_DIRECTIONS_LENGTH = 20  # Filter out recipes with too short directions

